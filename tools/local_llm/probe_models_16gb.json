{
  "models": ["qwen2.5:14b-instruct", "llama3.1:latest", "mistral:latest"],
  "tier": "16gb",
  "vram_max_gib": 16,
  "notes": "RTX 4080, RTX 4060 Ti 16GB, RTX 5080. Fits 14B models."
}
